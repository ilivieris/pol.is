{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import select_rows, sparsity_aware_dist, polis_umap, polis_pca\n",
    "# from utils.community_detection import polis_community_detection\n",
    "# from utils.subconversation import comment_visualization, polis_subconversation\n",
    "\n",
    "# Visualization parameters\n",
    "plt.figure(figsize=(500, 500));\n",
    "sns.set_context('poster');\n",
    "sns.set_style('white');\n",
    "sns.set(font_scale=.7);\n",
    "sns.set_color_codes();\n",
    "np.seterr(divide='ignore', invalid='ignore');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import participants votes\n",
    "df = pd.read_csv('Data/american-assembly.bowling-green/participants-votes.csv',index_col='participant')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import participants' comments\n",
    "df_comments = pd.read_csv('Data/american-assembly.bowling-green/comments.csv',index_col='comment-id')\n",
    "df_comments.index = df_comments.index.astype(str)\n",
    "df_comments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set Metadata fields and variable fields\n",
    "metadata_fields = ['group-id', 'n-comments', 'n-votes', 'n-agree', 'n-disagree']\n",
    "val_fields = [c for c in df.columns.values if c not in metadata_fields]\n",
    "\n",
    "# remove statements (columns) which were moderated out\n",
    "# df_comments[\"moderated\"] = 0   --->   comment should be removed\n",
    "statements_all_in = sorted(list(df_comments.loc[df_comments[\"moderated\"] > 0].index.array), key = int)\n",
    "\n",
    "# Remove participants with less than N (threshold) votes.\n",
    "df = select_rows(df=df, val_fields=val_fields, threshold=60)\n",
    "\n",
    "# Preprocess\n",
    "metadata = df[metadata_fields]\n",
    "vals = df[val_fields]\n",
    "# If the participant didn't see the statement, it's a null value, here we fill in the nulls with zeros\n",
    "vals = vals.fillna(0)\n",
    "vals = vals.sort_values(\"participant\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = vals.melt();\n",
    "all_votes = melted.count();\n",
    "by_type = melted[\"value\"].value_counts();\n",
    "total_possible_votes = all_votes[\"value\"];\n",
    "total_agrees = by_type[1.0];\n",
    "total_disagrees = by_type[-1.0];\n",
    "total_without_vote = by_type[0.0];\n",
    "\n",
    "print(\"Dimensions of matrix:\", df.shape)\n",
    "print(\"Dimensions of matrix:\", vals.shape)\n",
    "print(\"Total number of possible votes:\", total_possible_votes)\n",
    "print(\"Total number of agrees:\", total_agrees)\n",
    "print(\"Total number of disagrees:\", total_disagrees)\n",
    "print(\"Total without vote:\", total_without_vote)\n",
    "print(\"Percent sparse: \", total_without_vote / total_possible_votes,\"%\")\n",
    "\n",
    "## Make sure to check how many people and votes, relative to the total matrix, you are losing given min vote threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_all_in = vals[statements_all_in]\n",
    "\n",
    "high_variance = [\"20\",\"26\",\"90\"]\n",
    "vals_high_variance = vals[high_variance]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinion matrix \n",
    "\n",
    "**Opinion matrix = Full participants * comments matrix**\n",
    "\n",
    "- How sparse is the dataset? How much agree, how much disagree, how much pass? Zero is 'passed' or 'did not see the comment to vote on it'. 1 is agree, -1 is disagree\n",
    "\n",
    "- Some things to notice about the matrix: comments are submitted over time, so participants who do not return will only have voted on the statements which were available when they arrived. \n",
    "\n",
    "- Long horizontal lines: participants who do return show up as a horizontal line sticking out into otherwise blank areas\n",
    "\n",
    "- Blank vertical lines: most likely statements which were moderated out of the conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check sparcity of 'Opinion Matrix'\n",
    "fig, ax = plt.subplots(figsize=(14,14));\n",
    "sns.heatmap(vals_all_in, center=0, cmap=\"RdYlBu\", ax=ax, cbar=False);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the space explained by how much people vote?\n",
    "\n",
    "In this chart, we take the PCA coordinates and color the participant locations by the number of total votes. Hopefully, it looks random. If it doesn't, we might imagine the following scenario:\n",
    "\n",
    "1. 1000 people vote, and there are very few controversial statements. They do not return.\n",
    "2. 1 person submits a statement which is incredibly controversial. \n",
    "3. 1000 more people vote, the space begins to take on structure, PCA is closely linked to vote count.\n",
    "\n",
    "We know this scenario - that voters don't see controversial comments - happens. Polis mitigates in two ways:\n",
    "* polis eliminates participants who don't vote at least 7 times from the analysis\n",
    "* polis shows several highly controversial comments (large egeinvalue) in the first 10 comments participants see"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application example\n",
    "- Communities detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polis_heatmap(__dataframe):\n",
    "    leidenClusters = polis_community_detection(__dataframe, 8)\n",
    "\n",
    "    # Show clustermap\n",
    "    __dataframe['leiden_cluster_assignments'] = leidenClusters\n",
    "    clusters_by_comments_means = __dataframe.groupby('leiden_cluster_assignments').agg('mean').T\n",
    "\n",
    "    index_to_label = df_comments['comment-body'].to_dict() # {index: label}\n",
    "\n",
    "    clustergrid = sns.clustermap(clusters_by_comments_means, cmap=\"RdBu\", figsize=(10,10), )\n",
    "\n",
    "    ax = clustergrid.ax_heatmap\n",
    "    new_labels = [index_to_label[str(idx._text)] for idx in ax.get_yticklabels()] # [ label0, label1, label2, ...]\n",
    "    ax.set_yticklabels(new_labels, rotation=0, fontsize=10)\n",
    "    \n",
    "    \n",
    "polis_heatmap(vals_high_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import leidenalg\n",
    "import louvain\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from utils.community_detection import show_embedding\n",
    "\n",
    "\n",
    "# Thanks to https://github.com/ciortanmadalina/high_noise_clustering/blob/master/graph-partitioning-louvain.ipynb\n",
    "def polis_community_detection(dataframe=None, neighbors=2, type='Leiden', metric=sparsity_aware_dist):\n",
    "    '''\n",
    "        Pol.is community detection using kNN graph\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: dataframe with participants votes\n",
    "        neighbors: number of neighbors (default=2)\n",
    "        type: 'Leiden' (default) or 'Louvain'\n",
    "        metric: distance metric\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Clusters obtaining the communities\n",
    "    '''\n",
    "    # Community detection\n",
    "    A = kneighbors_graph(\n",
    "        dataframe.values, \n",
    "        neighbors, \n",
    "        mode=\"connectivity\",  \n",
    "        metric=metric,        \n",
    "        metric_params=None, \n",
    "        include_self=True, \n",
    "        n_jobs=None\n",
    "    )\n",
    "\n",
    "    sources, targets = A.nonzero()\n",
    "    weights = A[sources, targets]\n",
    "    if isinstance(weights, np.matrix): # ravel data\n",
    "            weights = weights.A1\n",
    "\n",
    "    g = ig.Graph(directed=False)\n",
    "    g.add_vertices(A.shape[0])  # each observation is a node\n",
    "    edges = list(zip(sources, targets))\n",
    "    g.add_edges(edges)\n",
    "\n",
    "    g.es['weight'] = weights\n",
    "    weights = np.array(g.es[\"weight\"]).astype(np.float64)\n",
    "\n",
    "    if (type == 'Leiden'):\n",
    "        # Clustering based on Leidenalg\n",
    "        part = leidenalg.find_partition(g, leidenalg.ModularityVertexPartition);\n",
    "        Clusters = np.array(part.membership)        \n",
    "    else:        \n",
    "        # Clustering based on Louvain algorithm\n",
    "        resolution_parameter = 1.5\n",
    "        partition_type = louvain.RBConfigurationVertexPartition\n",
    "        partition_kwargs = {\"weights\": weights, \"resolution_parameter\": resolution_parameter}\n",
    "        part = louvain.find_partition(g, partition_type, **partition_kwargs)\n",
    "        Clusters = np.array(part.membership)\n",
    "\n",
    "    return Clusters\n",
    "\n",
    "\n",
    "\n",
    "def polis_community_detection(dataframe, clustering_type='Leiden', comments=None):\n",
    "    print('[INFO] Application of PCA', end=': ')\n",
    "    coords, explained_variance = polis_pca(dataframe, 2)\n",
    "    print('Complete')\n",
    "    print(\"Explained variance:\", explained_variance)\n",
    "\n",
    "    print('[INFO] Application of UMAP', end=': ')\n",
    "    embedding = polis_umap(dataframe, 4);\n",
    "    print('Complete')\n",
    "\n",
    "    print(f'[INFO] Application of {clustering_type} clustering', end=': ')\n",
    "    leidenClusters = polis_community_detection(dataframe=dataframe, neighbors=8, type=clustering_type)\n",
    "    print('Complete')\n",
    "    print('[INFO] Number of communities (clusters): ', np.unique(leidenClusters).shape[0])\n",
    "    \n",
    "\n",
    "    # Show clusters given PCA embedding \n",
    "    title = f\"{clustering_type} detected communities in PCA space\"\n",
    "    show_embedding(coords, leidenClusters, title)   \n",
    "    \n",
    "    # Show clusters given umap embedding \n",
    "    title = f\"{clustering_type} detected communities in UMAP space\"\n",
    "    show_embedding(embedding, leidenClusters, title)   \n",
    "    \n",
    "    \n",
    "    # Show clustermap\n",
    "    dataframe['cluster_assignments'] = leidenClusters\n",
    "    clusters_by_comments_means = dataframe.groupby('cluster_assignments').agg('mean')\n",
    "\n",
    "    sns.heatmap(clusters_by_comments_means, cmap=\"RdYlBu\")\n",
    "    sns.clustermap(clusters_by_comments_means, cmap=\"RdYlBu\")\n",
    "\n",
    "    return coords, embedding, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coords, embedding, _ = polis_subconversation(vals_all_in.iloc[:20,:100], clustering_type='Leiden', comments=['5'])\n",
    "\n",
    "# coords, embedding, _ = polis_subconversation(vals_all_in.iloc[:,:100], clustering_type='Louvain', comments=['5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import comment_visualization\n",
    "\n",
    "comments_ids = ['4', '5']\n",
    "\n",
    "# Opinion of select community about specific comments\n",
    "for x in comments_ids:\n",
    "    comment = df_comments['comment-body'][x]\n",
    "    comment_visualization(dataframe=vals_all_in, comment_id=x, comment=comment, coords=coords, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3408c1ac7e23b962066ab3f3326bf33ee7faf6774785b00c32de53a33f53a208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
